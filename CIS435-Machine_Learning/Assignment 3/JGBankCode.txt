# James Gray - Northwestern University CIS435 - Assignment #3 (August 2, 2014)
# Bank Marketing Study

# original source data from http://archive.ics.uci.edu/ml/datasets/Bank+Marketing 

from __future__ import division, print_function
from future_builtins import ascii, filter, hex, map, oct, zip

import sklearn as sk
import sklearn.linear_model as sklm
import numpy as np  # efficient processing of numerical arrays
import pandas as pd  # pandas for data frame operations
import matplotlib.pyplot as plt  # for plotting ROC curve
import sklearn.svm as svm # support vector machine learner
import sklearn.naive_bayes as nb # naive bayes learner
  

# use the full data set after development is complete with the smaller data set
# bank = pd.read_csv('bank-full.csv', sep = ';')  # start with smaller data set

# data set predictors
# age: numeric
# job : type of job (categorical: 'admin.','blue-collar','entrepreneur','
#    housemaid','management','retired','self-employed','services','student',
#    'technician','unemployed','unknown')
# marital : marital status (categorical: 'divorced','married','single','unknown'; 
#    note: 'divorced' means divorced or widowed)
# education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','
#    illiterate','professional.course','university.degree','unknown')
# default: has credit in default? (categorical: 'no','yes','unknown')
# balance: ?
# housing: has housing loan? (categorical: 'no','yes','unknown')
# loan: has personal loan? (categorical: 'no','yes','unknown')
# contact: contact communication type (categorical: 'cellular','telephone') 
# day: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')
# month: last contact month of year (categorical: 'jan', 'feb', 'mar'....)
# duration: last contact duration, in seconds (numeric). Should be removed
# campaign: number of contacts performed during this campaign and for this client\
#    (numeric, includes last contact)
# pdays: number of days that passed by after the client was last contacted from 
#    a previous campaign (numeric; 999 means client was not previously contacted)
# previous: number of contacts performed before this campaign and for this client (numeric)
# poutcome: outcome of the previous marketing campaign (categorical: 'failure',
#    'nonexistent','success')
# y - has the client subscribed a term deposit? (binary: 'yes','no')


# initial work with the smaller data set
bank = pd.read_csv('bank.csv', sep = ';')  # start with smaller data set
# drop observations with missing data, if any
bank.dropna()

# examine the shape of the DataFrame
print(bank.shape)

# look at the list of column names, note that y is the response
list(bank.columns.values)

# look at the beginning of the DataFrame
print (bank.head())

# define response variable of use in the model
convert_to_binary = {'no' : 0, 'yes' : 1}
y = bank['y'].map(convert_to_binary)

# define binary variable for having credit in default
default = bank['default'].map(convert_to_binary)

# define binary variable for having a personal loan
housing = bank['housing'].map(convert_to_binary)

# define binary variable for having a personal loan
loan = bank['loan'].map(convert_to_binary)

# use average yearly balance in euros as explanatory variable
balance = bank['balance']

# number of previous contacts
previous = bank['previous']

# age array
age = bank['age']

# job array
job = bank['job']

# marital status
marital = bank['marital']

# education array
education = bank['education']

# month array
#month = bank['month']

# The "day" was not used since the value is meaningless

# gather these explanatory variables into a numpy array 
# here we use .T to obtain the transpose for the structure we want
x = np.array([np.array(default), np.array(housing), np.array(loan), 
    np.array(balance), np.array(previous)]).T

    
# =============================================================================
# LOGISTIC REGRESSION
# =============================================================================

# fit a logistic regression model 
# note differences with and without class_weight settings
# by using class_weight = 'auto' argument in LogisticRegression
logreg = sklm.LogisticRegression(C=1e5)
my_model_fit = logreg.fit(x, y)

# predicted class in training data only
y_pred = my_model_fit.predict(x)
print('Logistic Confusion matrix for training set')
print(sk.metrics.confusion_matrix(y, y_pred))
print('Logistic Predictive accuracy in training set:',round(sk.metrics.accuracy_score(y, y_pred), 3))

# multi-fold cross-validation with 5 folds
cv_results = sk.cross_validation.cross_val_score(logreg, x, y, cv=5)
print('Logistic Cross-validation average accuracy:', round(cv_results.mean(),3))  

# compute ROC curve and area under the ROC curve
probs = my_model_fit.predict_proba(x)
false_positive, true_positive, thresholds = sk.metrics.roc_curve(y, probs[:, 1])
roc_auc = sk.metrics.auc(false_positive, true_positive)
print('Logistic Area under the ROC curve:', round(roc_auc,3))

# Plot ROC curve to IPython shell and to external file
plt.clf()
plt.plot(false_positive, true_positive, label='ROC Curve (area = %0.3f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Logistic Regression')
plt.legend(loc="lower right")
plt.savefig('plot_roc.pdf')

# =============================================================================
# SUPPORT VECTOR MACHINE (SVM)
# =============================================================================

svmclf = svm.SVC(probability=True)
svm_fit = svmclf.fit(x, y) 

# predict class using training data
y_svmpred = svm_fit.predict (x)
print(sk.metrics.confusion_matrix(y, y_svmpred))
print('SVM Predictive accuracy in training set:',round(sk.metrics.accuracy_score(y, y_svmpred), 3))

# SVM multi-fold cross-validation with 5 folds
svm_cv_results = sk.cross_validation.cross_val_score(svmclf, x, y, cv=5)
print('SVM Cross-validation average accuracy:', round(svm_cv_results.mean(),3)) 

# compute ROC curve and area under the ROC curve
svm_probs = svm_fit.predict_proba(x)
false_positive, true_positive, thresholds = sk.metrics.roc_curve(y, probs[:, 1])
svm_roc_auc = sk.metrics.auc(false_positive, true_positive)
print('SVM Area under the ROC curve:', round(svm_roc_auc,3))

# Plot ROC curve to IPython shell and to external file
plt.clf()
plt.plot(false_positive, true_positive, label='ROC Curve (area = %0.3f)' % svm_roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for SVM')
plt.legend(loc="lower right")
plt.savefig('svm_plot_roc.pdf')
 
